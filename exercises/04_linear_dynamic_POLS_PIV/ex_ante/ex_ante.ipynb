{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem set 4: Dynamic linear models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from numpy import linalg as la\n",
    "from tabulate import tabulate \n",
    "import pandas as pd \n",
    "import LinearDynamic as lm\n",
    "import seaborn as sns\n",
    "sns.set_theme();\n",
    "\n",
    "np.set_printoptions(precision=5)\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare the data\n",
    "\n",
    "In this problem set, we consider the question of state dependence in **firm revenue** ($y$). The data, `cvr_extract.csv`, comes from the Danish register of firms, \"CVR registret\". It can be reconstructed or modified by downloading the tax files from [skst.dk](https://www.sktst.dk/aktuelt/skatteoplysninger-for-selskaber/) and running the notebook `clean_data.ipynb`. The accompanying notebook, `analysis.ipynb`, does some overly simplistic analyzing that illustrates some questions one might want to explore with the data. \n",
    "\n",
    "**Research question:** Should we provide assistance to firms? If adverse shocks (such as a pandemic) are very persistent, then we want to provide a safety net for firms. Conversely, if firms just rebound after a shock, that can be a waste of tax funds. \n",
    "\n",
    "The data consists of all firms observed in every year from 2012-2019, which satisfy that the net income (pre-tax) was below 10 mio. DKK. The variables in the data are: \n",
    "\n",
    "  |*Variable*  | *Content* |\n",
    "  |------------| --------------------------------------------|\n",
    "  |`net_inc`          | Net income (`income - deficit`) |\n",
    "  |`taxable_income`          | Income |\n",
    "  |`deficit`          | Losses |\n",
    "  |`tax`          | Tax payment |\n",
    " | `cat`         | A categorical variable, based on the dummies, `dum_X` below |\n",
    "  | `dum_X`          | Dummy for whether the firm's name contains the string `X` (in Danish) |\n",
    "  \n",
    "  The dummies, e.g. `dum_doctor`, are explained below \n",
    "\n",
    "| **Substring** | **If name contains** | \n",
    "| ---- | ------ | \n",
    "| `as` | 'a/s' | \n",
    "| `aps` | 'aps' | \n",
    "| `ivs` | 'ivs' | \n",
    "| `ab` | 'a/b' | \n",
    "| `realestate` | 'ejendom' | \n",
    "| `holding` | 'holding' | \n",
    "| `invest` | 'invest' | \n",
    "| `consult` | 'consult' | \n",
    "| `service` | 'service' | \n",
    "| `dot_dk` | '.dk' | \n",
    "| `doctor` | 'læge' | \n",
    "| `carpenter` | 'tømrer' | \n",
    "| `transport` | 'transport' or 'lastvogn' | \n",
    "| `plumbing` | 'vvs' or 'kloak' | \n",
    "| `import` | 'import' | \n",
    "| `masonry` | 'murer' | \n",
    "| `nielsen` | 'nielsen' | \n",
    "| `sorensen` | 'sørensen' | "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat = pd.read_csv('cvr_extract.csv')\n",
    "dat.sample(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Descriptives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax=dat.groupby('year').net_inc.sum().plot(marker='o'); \n",
    "ax.set_ylabel('Total firm revenue'); "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = dat.groupby('cat').taxable_income.count().plot(kind='bar'); \n",
    "ax.set_ylabel('Observations'); "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = dat.groupby('cat').taxable_income.mean().plot(kind='bar'); \n",
    "ax.set_ylabel('Avg. net income'); "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax=dat.groupby(['year', 'cat']).taxable_income.mean().unstack().plot(marker='o'); \n",
    "ax.set_ylabel('Firm profits (avg.)'); \n",
    "ax.legend(title='Firm name contains', loc=(1.05,0.3)); "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set up data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # select only firms that are in transport in all years \n",
    "# I = dat.groupby('firmid').dum_realestate.transform('all')\n",
    "# dat = dat[I].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convenient list of the names of all the dummy variables\n",
    "cols_dum = [c for c in dat.columns if c == 'dum_']\n",
    "\n",
    "# convert int->bool \n",
    "for c in cols_dum: \n",
    "    dat[c] = dat[c].astype('bool')\n",
    "\n",
    "N = dat.firmid.unique().size\n",
    "T = dat.year.unique().size\n",
    "print(f'Data has {dat.shape[0]:,d} rows: N = {N:,d}, T = {T}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# measure money in 1000 DKK \n",
    "for v in ['net_inc', 'taxable_income', 'deficit', 'tax']: \n",
    "    dat[v] = dat[v] / 1000."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat['lag_net_inc'] = dat.groupby('firmid').net_inc.shift(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pandas to numpy "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "I = dat.lag_net_inc.notnull() # cannot use first year: no lagged variable \n",
    "T = dat[I].year.unique().size\n",
    "N = dat[I].firmid.unique().size\n",
    "\n",
    "assert dat[I].shape[0] == N*T, 'Data is not a balanced panel'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = dat[I].net_inc.values.reshape((-1,1))\n",
    "y_l = dat[I].lag_net_inc.values.reshape((-1,1))\n",
    "const = np.ones((N*T,1))\n",
    "x = np.column_stack((const, y_l))\n",
    "\n",
    "ylbl = 'profit'\n",
    "xlbl = ['const', 'lagged profit']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 1: POLS\n",
    "Today we will focus on a parsimonious model of profit $\\pi$ (econometricians often use \"parsimonious\" to mean a \"simple\"). \n",
    "\n",
    "Consider first the following AR(1) (autoregressive model of order $1$),\n",
    "\n",
    "$$\n",
    "\\pi_{it} = \\alpha_0 +  \\rho \\pi_{it-1} + c_i + u_{it}, \\quad t = 1, 2, \\dotsc, T \\tag{1}\n",
    "$$\n",
    "\n",
    "As we have seen before, if one does not take into consideration $c_i$ when estimating $\\rho$, one will get biased results. One way to solve this, which is also a common way for AR(1) processes, is to take first-differences. We then have the model,\n",
    "\n",
    "$$\n",
    "\\Delta \\pi_{it} = \\rho \\Delta \\pi_{it-1} + \\Delta u_{it}, \\quad t = 2, \\dotsc, T \\tag{2}\n",
    "$$\n",
    "\n",
    "This solves the presence of fixed effects."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 1\n",
    "Estimate eq. (1) using POLS. \n",
    "* Are there signs of autocorrelation in profit?\n",
    "* What assumptions are no longer satisfied? What happens with fixed effects when we include a lag?\n",
    "\n",
    "*Note:* We need to use the lagged values for participation. But this time we don't need to lag it ourselves, as it is already given to us in the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FILL IN\n",
    "# Estimate the AR(1) model using OLS\n",
    "# Print out in a nice table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Your table should look like this:\n",
    "\n",
    "\n",
    "AR(1)\n",
    "Dependent variable: profit\n",
    "\n",
    "|              |  Beta |     Se|   t-values | \n",
    "|------------- | ------|  -------|  ----------|\n",
    "|const   |       33.037 | 0.98750 |      33.46|\n",
    "|lagged profit |  0.589 | 0.00629  |     93.75| \n",
    "R² = 0.328\n",
    "σ² = 402764.374"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 2\n",
    "Estimate eq. (2) using first differences. \n",
    "* What problem does this solve? \n",
    "* What type of exogeneity assumption is used to justify this method of estimation?\n",
    "\n",
    "*Note:* You have to create the first differencing matrix yourself, and use the `perm` function to permutate the dependen and independent variables. <br>\n",
    "*Note 2:* This time you should use robust standard errors. The function is provided to you."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FILL IN\n",
    "# Create a first difference matrix\n",
    "# First difference both profit and lag of profit\n",
    "# Estimate AR(1) model using OLS and print a nice table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Your table should look like this:\n",
    "\n",
    "FD AR(1) <br>\n",
    "Dependent variable: profit\n",
    "\n",
    "|              |   Beta |     Se |   t-values |\n",
    "|------------- | ------ | ------ | ---------- |\n",
    "|lagged profit | -0.410 | 0.0056 |     -73.13 |\n",
    "R² = 0.160\n",
    "σ² = 427320.714"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Super short introduction to pooled IV (piv)\n",
    "\n",
    "Consider that we want to estimate the effect of $x_K$ on $y$, including $K - 1$ controls, we then have the usual equation,\n",
    "\n",
    "$$\n",
    "\\mathbf{y} = \\mathbf{X} \\boldsymbol{\\beta} + \\mathbf{u} \\tag{3}\n",
    "$$\n",
    "\n",
    "where $\\mathbf{X} = (\\mathbf{x}_1, \\dotsc, \\mathbf{x}_K)$. If $\\mathbf{x}_K$ is not exogenous, we can define the instrument vector $\\mathbf{Z} = (\\mathbf{x}_1, \\dotsc, \\mathbf{x}_{K - 1}, \\mathbf{z}_1)$, where $\\mathbf{z}_1$ is an instrument for $\\mathbf{x}_K$. The details and necessary assumptions and conditions are outlined in Wooldridge (2010) (chapter 5).\n",
    "\n",
    "We can estimate eq. (1) by OLS using $z_1$ as an instrument for $x_K$, in order to make it easier for you when writing code, I write it up in matrix notation,\n",
    "\n",
    "$$\n",
    "\\boldsymbol{\\hat{\\beta}} = (\\mathbf{\\hat{X'}}\\mathbf{\\hat{X}})^{-1} \\mathbf{\\hat{X'}}\\mathbf{Y}, \\tag{4}\n",
    "$$\n",
    "\n",
    "where $\\mathbf{\\hat{X}} = \\mathbf{Z}(\\mathbf{Z'}\\mathbf{Z})^{-1}\\mathbf{Z'}\\mathbf{X}$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 2: Pooled IV\n",
    "It should not be a surprise that models (1) and (2) violates the strict exegoneity assumption, but even if we relax this assumption to sequential exegoneity, the FD-estimator remains inconsistent.\n",
    "\n",
    "A solution for this is to use an instrument for $\\Delta \\pi_{it-1}$. The biggest issue is to find an instrument that is not only relevant, but also exogenous.\n",
    "\n",
    "We often use an additional lag as instruments. So for $\\Delta \\pi_{it-1}$, we can use $\\pi_{it-2}$. In general, we have all possible lags available as instruments. So for $\\Delta \\pi_{it-1}$ we have, $\n",
    "\\pi_{it-2}^{\\textbf{o}} = (\\pi_{i0}, \\pi_{i1}, \\dotsc \\pi_{it-2})$ available as instruments.\n",
    "\n",
    "*Note:* $R^2$ has no meaning in IV-regressions, you can report it if you want to. But I set it to 0."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 1\n",
    "Estimate eq. (2) by using the lag of the independent variable in levels, $z_{it} = \\pi_{it-2}$ as an instrument. You need to finish writing the `est_piv` function and a part of the `estimate` function.\n",
    "\n",
    "*Note:* In the estimate function, the variance function takes x as an argument. But we want to pass the `variance` function $\\mathbf{\\hat{X}}$ instead. <br>\n",
    "*Note 2:* In order to create the instrument, you need to create a lag matrix, and use `perm`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FILL IN\n",
    "# Create first a lag matrix\n",
    "# Lag the lagged profit variable\n",
    "# Finish writing the piv function\n",
    "# Finish writing the estimate function\n",
    "# Estimate using first differences and lagged first differences. Use the 2. lag as instrument."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Your table should look like this:\n",
    "\n",
    "FD-IV AR(1) <br>\n",
    "Dependent variable: delta profit\n",
    "\n",
    "|                   |   Beta |     Se |   t-values |\n",
    "|-------------------|--------|--------|------------|\n",
    "| lagged profit     |  0.153 |  0.0112|      13.63 | \n",
    "R² = n.a. <br>\n",
    "σ² = 580426.756"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 2\n",
    "Estimate eq. (2) by using the lag of the independent variable in first differences, $z_{it} = \\Delta \\pi_{it-2}$ as an instrument."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FILL IN\n",
    "# Lag the first differenced lag profit variable\n",
    "# The second lag uses up an extra observation, so you need to use the year variable to shorten both first differenced profit and the 1. first difference lag.\n",
    "# Estimate using first differences and lagged first differences. Use the 2. first difference lag as instrument."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new lag matrix (that is shorter, since we already removed one obs)\n",
    "# Create second lag of first differences.\n",
    "L_t = lag(T - 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat['diff_net_inc']      = dat.groupby('firmid').net_inc.diff()\n",
    "dat['lag_diff_net_inc']  = dat.groupby('firmid').diff_net_inc.shift(1)\n",
    "dat['lag2_diff_net_inc'] = dat.groupby('firmid').diff_net_inc.shift(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "I = dat.lag2_diff_net_inc.notnull()\n",
    "yfd    = dat[I].diff_net_inc.values.reshape((-1,1))\n",
    "yfd_l1 = dat[I].lag_diff_net_inc.values.reshape((-1,1))\n",
    "yfd_l2 = dat[I].lag2_diff_net_inc.values.reshape((-1,1))\n",
    "\n",
    "assert (dat.groupby('firmid').year.size() == dat.year.unique().size).all(), 'not balanced'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Remove the first observation for each person.\n",
    "# reduced_year = year[year != 1986]  # Remove first year, so that shape is the same as yfd\n",
    "# yfd0 = yfd[reduced_year != 1987]\n",
    "# yfd_l0 = yfd_l[reduced_year != 1987]\n",
    "\n",
    "# Alternatively, you can use the vectors \n",
    "# yfd\n",
    "# yfd_l1 \n",
    "# yfd_l2\n",
    "# that are already created for you above. \n",
    "\n",
    "# FILL IN \n",
    "# ar1_iv_result = lm.estimate(...)\n",
    "# lm.print_table(...)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Your table should look like this:\n",
    "FD-IV AR(1) <br>\n",
    "Dependent variable: delta profit\n",
    "\n",
    "|                   |   Beta |     Se |   t-values |\n",
    "|-------------------|--------|--------|------------|\n",
    "| lag delta profit|  -0.005 | 0.0193 |       -0.28 |\n",
    "R² = n.a <br>\n",
    "σ² = 529085.073"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summing up Exercise 1 and 2.\n",
    "\n",
    "First of all, try to consider if it is more obvious to use $\\pi_{it-2}$ or $\\Delta \\pi_{it-2}$ as an instrument for $\\Delta \\pi_{it-1}$?\n",
    "\n",
    "Then consider how do the different models compare to each other, some questions that you might discuss with your classmates could be:\n",
    "* Which ones do you feel gives most sense from an economic perspective. \n",
    "* Which ones gives most sense from an econometric perspective? \n",
    "* Do you feel that there is conclusive evidence that there is state dependence in profit?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 1: Create the level instrument matrix $\\mathbf{Z^{\\mathbf{o}}}$\n",
    "\n",
    "Finish the function `sequential_instruments` in order to create the instrument matrix $\\mathbf{Z^{\\mathbf{o}}}$ using the second lag of profit in **levels**. Note that you will not have one array that looks like $\\mathbf{Z^{\\mathbf{o}}}$, but an array that have something that looks like $\\mathbf{Z^{\\mathbf{o}}}$ for each individual in the data. Since we have four time periods, and access to $y_{i0}$, you should get three rows of instruments for each individual.\n",
    "\n",
    "$$\n",
    "\\mathbf{Z^{\\mathbf{o}}} = \n",
    "\\begin{bmatrix}\n",
    "    y_{i0} & 0 & 0 & 0 & 0 & 0 & \\cdots & 0 \\\\\n",
    "    0 & y_{i0} & y_{i1} & 0 & 0 & 0 & \\cdots & 0 \\\\\n",
    "    0 & 0 & 0 & y_{i0} & y_{i1} & y_{i2} & \\cdots & 0 \\\\\n",
    "    \\vdots  & \\vdots & \\vdots & \\vdots & \\vdots & \\vdots & \\ddots & \\vdots \\\\\n",
    "    0 & 0 & 0 & 0 & 0 & 0 & \\cdots & \\mathbf{y^o_{it-2}} \\\\\n",
    "\\end{bmatrix}\n",
    "\\begin{pmatrix}\n",
    "t = 2 \\\\\n",
    "t = 3 \\\\\n",
    "t = 3 \\\\\n",
    "\\vdots \\\\\n",
    "t = T\n",
    "\\end{pmatrix}.\n",
    "$$\n",
    "\n",
    "If if is too difficult to create the instrument matrix $\\mathbf{Z^{\\mathbf{o}}}$, you could also in this instance hard code it. This can be done by using the year column to do boolean indexing in python. You can then use the `np.hstack` to create the necessary columns for the first stage regressions. Look at *question 2* below if you are uncertain on how many columns you should have for each regression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gmm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "instrument_matrix = gmm.sequential_instruments(y_2l, T)\n",
    "print(instrument_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To prepeare for next question, I have created an function that retrieves one time period for each person, and store them in seperate arrays, and finaly returns these in a list. (I also keep the array for the all time periods, since we need that for the second stage regression). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def xy_eq_by_eq(x, t):\n",
    "    equation = []\n",
    "    # Reshape, so that each column is each time period\n",
    "    xt = x.reshape(-1, t)\n",
    "\n",
    "    # I then transpose this, so that each time period is in rows\n",
    "    for row in xt.T:\n",
    "        # I then put each time period in a separate array, that I store in the list.\n",
    "        equation.append(row.reshape(-1, 1))\n",
    "    # We need individual observations for all years in the second stage regression,\n",
    "    # so let us keep that at the end of the list.\n",
    "    equation.append(x)\n",
    "    return equation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reset: now we no longer need to delete *3* years but only 2. \n",
    "I = dat.lag_diff_net_inc.notnull()\n",
    "yfd    = dat[I].diff_net_inc.values.reshape((-1,1))\n",
    "yfd_l  = dat[I].lag_diff_net_inc.values.reshape((-1,1))\n",
    "years  = dat[I].year.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_arrays = xy_eq_by_eq(FILL IN)\n",
    "x_arrays = xy_eq_by_eq(FILL IN)\n",
    "print(y_arrays)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 2: Use the instruments to perform 2SLS\n",
    "\n",
    "Now that you have the necessary instruments, use these to estimate eq. (2), with all possible lagged levels as instruments.\n",
    "\n",
    "I recommend that you create two functions for this. One that simply performs the first-stage regression given y and x, let's call it `first_stage`, and should return the predicted $\\hat{\\mathbf{x}}_K$, which in this case is the second lagged \\pi.\n",
    "\n",
    "The second function, let us call is `system_2sls`, loops over a list of y, x and z arrays that are given as inputs, and performs the `first_stage` regression on each array (remember, each array has all observations from one time period only). Since the `first_stage` function you made returns the predicted $\\hat{\\mathbf{x}}_K$, you need to keep them, and in the end combine them. You can now perform the second-stage regression.\n",
    "\n",
    "So in our example where we use levels, you should perform three first-stage regressions that look like this:\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "\\Delta \\pi_{i1987} & = \\rho_{11}\\pi_{i1986} + u_{it} \\\\\n",
    "\\Delta \\pi_{i1988} & = \\rho_{21}\\pi_{i1986} + \\rho_{22}\\pi_{i1987} + u_{it} \\\\\n",
    "\\Delta \\pi_{i1989} & = \\rho_{31}\\pi_{i1986} + \\rho_{32}\\pi_{i1987} + \\rho_{33}\\pi_{i1988} + u_{it} \\\\\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "Then, for each regression, you also need to predict the \\pi. These need to be stored and in the end combined, so that you get a column that looks like this,\n",
    "\n",
    "$$\n",
    "\\underset{N(T - 1) \\times 1}{\n",
    "\\begin{pmatrix}\n",
    "    \\Delta \\widehat{\\pi}_{1, 1987} \\\\\n",
    "    \\Delta \\widehat{\\pi}_{1, 1988} \\\\\n",
    "    \\Delta \\widehat{\\pi}_{1, 1989} \\\\\n",
    "    \\Delta \\widehat{\\pi}_{2, 1987} \\\\\n",
    "    \\Delta \\widehat{\\pi}_{2, 1988} \\\\\n",
    "    \\Delta \\widehat{\\pi}_{2, 1989} \\\\\n",
    "    \\vdots \\\\\n",
    "    \\Delta \\widehat{\\pi}_{N, 1987} \\\\\n",
    "    \\Delta \\widehat{\\pi}_{N, 1988} \\\\\n",
    "    \\Delta \\widehat{\\pi}_{N, 1989} \\\\\n",
    "\\end{pmatrix}\n",
    "}\n",
    "$$\n",
    "\n",
    "So in the end, you perform a second stage regression that looks like this\n",
    "\n",
    "$$\n",
    "    \\Delta \\pi_{it} = \\rho\\Delta \\widehat{\\pi}_{it-1} + \\Delta u_{it}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I have created these helper functions. So if you managed to create the instrument matrix, \n",
    "# you can use the iv_eq_by_eq to get columns that give you the correct number of columns for \n",
    "# the different time periods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "instrument_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def IV_eq_by_eq(instrument_matrix, years):\n",
    "    yy = np.unique(years)\n",
    "    \n",
    "    # initialize \n",
    "    zz = []\n",
    "    this_row = 0 \n",
    "    \n",
    "    for t,y in enumerate(yy): \n",
    "        # the columns for this year \n",
    "        ii = slice(this_row, this_row+(t+1))\n",
    "        z = instrument_matrix[years == y, ii]\n",
    "        \n",
    "        # ensure matrix-form \n",
    "        if z.ndim == 1: \n",
    "            z.reshape(-1,1)\n",
    "        \n",
    "        # store results \n",
    "        zz.append(z)\n",
    "    \n",
    "        # how many rows we skipped this time (1, 2, 3, ...) -> this_row = (0, 1, 3, ..., 6)\n",
    "        this_row += t+1 \n",
    "\n",
    "    # return as a tuple\n",
    "    return zz\n",
    "\n",
    "z_arrays = IV_eq_by_eq(instrument_matrix, years)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s2sls_result = gmm.system_2sls(y_arrays, x_arrays, z_arrays)\n",
    "lm.print_table(\n",
    "    ('Delta y', ['Delta y_t-1']), s2sls_result, title='System 2SLS results', floatfmt='.4f'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "System 2SLS results <br>\n",
    "Dependent variable: yfd\n",
    "\n",
    "|       |   Beta |     Se |   t-values |\n",
    "|-------|--------|--------|------------|\n",
    "| Delta y_t-1 | 0.0215 | 0.0017 |    12.9911 |\n",
    "R² = 0.000 <br>\n",
    "σ² = 517249.527"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
